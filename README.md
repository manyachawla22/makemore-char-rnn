# mymakemore
# Makemore â€” Character-Level Language Model

This project is my personal reimplementation of the *Makemore* character-level language model from Andrej Karpathyâ€™s **"Neural Networks: Zero to Hero"** series.  
I followed the concepts step-by-step, rewrote the code in my own way, and added extra comments and explanations to strengthen my understanding of backpropagation, embeddings, and gradient flow.

## ðŸ“˜ Notebooks
- **makemore_part1.ipynb** â€” Bigram model basics  
- **makemore_part2.ipynb** â€” Adding hidden layers (MLP)  
- **makemore_part3.ipynb** â€” Improving training and analysis  
- **makemore_part4_backprop.ipynb** â€” Full manual backpropagation  

## ðŸ§  Key Learnings
- Character-level tokenization and generation  
- Implementing neural networks from scratch (NumPy + PyTorch)  
- Backpropagation and gradient updates  
- Fundamentals behind GPT-like architectures  

## ðŸ§© Tools Used
Python, NumPy, PyTorch, Matplotlib

## ðŸ“š Acknowledgement
Inspired by [Andrej Karpathyâ€™s NN Zero to Hero](https://github.com/karpathy/nn-zero-to-hero).  
This repo reflects my own implementation and understanding built through the series.
